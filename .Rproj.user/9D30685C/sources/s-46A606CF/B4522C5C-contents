
# select a particular fandom and media type
type <- c("anime", "book", "cartoon", "comic", "game", "misc", "movie", "play", "tv")

#--------------------------------------------------------------------------------------------
#--------------------------------------------------
# get all of the href story listings for all genres
# TO GENERATE typeMedia !!
#--------------------------------------------------

typeMedia <- list()
for(i in seq_along(type)){
  url <- paste0("https://www.fanfiction.net/", type[i]) 
  html <- paste(readLines(url), collapse="\n")
  matched <- str_match_all(html, "<a href=\"(.*?)\"")
  names <- str_match_all(html, "title=\"(.*?)\"")
  
  # temp<-data.frame()
  temp <- data.frame(href=matched[[1]][,2], title=names[[1]][,2])
  typeMedia[[i]] <- temp
  names(typeMedia)[i] <- type[i]
  temp<-NULL
}

# names(typeMedia)
# url <- "https://www.fanfiction.net/" 
# html <- paste(readLines(url), collapse="\n")
# matched <- str_match_all(html, "<a href=\"(.*?)\"")
# typeMedia <- data.frame()
# typeMedia[1] <- as.data.frame(matched$X2)
#--------------------------------------------------------------------------------------------
#--------------------------------------------------
# Get the url to the desired fandom
#--------------------------------------------------
getUrl <- function(story, type, max.entries=NA) {
  # look through typeMedia for href
  if(grepl("'", story)) {
    story<-str_split(story,"'")
    var <- "\\ \\'"
    var <- str_split(var, " ")
    story <- paste0(story[[1]][1], var[[1]][2], story[[1]][2])
  }

  rowVal <- grep(story,typeMedia[[type]]$title)
  href <- typeMedia[[type]]$href[rowVal[1]]
  # make desired url
  url <- paste0("https://www.fanfiction.net", href)
  returns <- list(url=url,max.entries=max.entries)
  return(returns)
}

#--------------------------------------------------------------------------------------------

#--------------------------------------------------
# get number of pages to iterate through
#--------------------------------------------------
getPages <- function(returns) {
  url <- returns[[1]]
  max.entries <- returns[[2]]
  returns <-list()
  library(rvest)
  
  page <- url %>% 
    read_html() %>% 
    html_nodes(xpath='//*[@id="content_wrapper_inner"]/center[1]/a[4]') %>% 
    html_attr("href")
    
    if(length(page)>0){ 
    # if there are multiple pages of entries
    page.g <- strsplit(page, "=", " ")
    page_num <- as.numeric(page.g[[1]][4])
    page_use <- as.character(gsub(page_num,"", page))
    
    returns <- list(noPages=FALSE, page_use=page_use, page_num=page_num, url=url, max.entries=max.entries)
  } else {
    returns <- list(noPages=TRUE, page_use=NA, page_num=NA,url=url, max.entries= max.entries)
  }
  
  return(returns)
}

#--------------------------------------------------------------------------------------------
#--------------------------------------------------
# scrape all entries; default, from all pages on the site available.
#--------------------------------------------------
getEntries <- function(returns) {
  
  noPages <- returns[[1]]
  page_use <- returns[[2]]
  page_num <- returns[[3]]
  url <- returns[[4]]
  max.entries <- returns[[5]]
  
  totalOut<-0

  scrapeEntries <- function(url, total){
    info <- character(0)
    total <- totalOut
    for(i in 4:28){
      if(!is.na(max.entries)) {if(max.entries - totalOut == 0) return(info)}
      entry <- url %>% read_html() %>% 
        html_nodes(xpath=paste('//*[@id="content_wrapper_inner"]/div[',i,']')) %>% 
        html_text()
      info <- c(info, entry)
      total<-total+1
      totalOut <<- total
    }
    return(info)
  }
  
  if(noPages==TRUE){
    entries <- scrapeEntries(url, totalOut)
    return(entries)
    
  } else {
    entries <- lapply(paste0('https://www.fanfiction.net/',page_use, 1:page_num),
                      scrapeEntries, total=totalOut)
    return(entries)
  }
  
}

#--------------------------------------------------------------------------------------------

#--------------------------------------------------
# get the entries from a given page
#--------------------------------------------------

all_entries<-function(entries) {
  library(qdapRegex)
  library(stringr)
  library(dplyr)
  
  makeDF <- function(entries) {
    full <- data.frame(matrix(NA, nrow = length(entries), ncol = 13))
    names(full) <- c("name","author","description","rating","language","theme",
                     "chapters","words","reviews","favs","follows","updated",
                     "published")
    # extract entry names
    t<-str_match(entries, "(.)+")
    t<-str_split(t[,1], " by ")
    # str_extract(string = entries1, pattern = perl("(?<=\n\t).*(?=Rating:)"))
    summary <- rm_between(entries[i], "\\n\t", "Rated:", extract=TRUE)
    
    
    test <- strsplit(entries, "Rated:")
    
    for(i in seq_along(entries)) {
      name <- trimws(t[[i]][1])
      author <- trimws(gsub(" reviews", "", t[[i]][2]))
      description <- rm_between(entries[i], "\\n\t", "Rated:", extract=TRUE)
      
      summaries<-strsplit(test[[i]][2], " - ")
      rating <- trimws(summaries[[1]][1])
      language <- summaries[[1]][2]
      theme <- summaries[[1]][3]
      chapters <- trimws(gsub("Chapters: ", "", str_match(test[[i]][2], "Chapters: [0-9,]+ ")))
      words <- trimws(gsub("Words: ", "", str_match(test[[i]][2], "Words: [0-9,]+ ")))
      reviews <- trimws(gsub("Reviews: ", "", str_match(test[[i]][2], "Reviews: [0-9,]+ ")))
      favs <- trimws(gsub("Favs: ", "", str_match(test[[i]][2], "Favs: [0-9,]+ ")))
      follows <- trimws(gsub("Follows: ", "", str_match(test[[i]][2], "Follows: [0-9,]+ ")))
      updated <- rm_between(test[[i]][2], "Updated: ", " - ", extract=TRUE)
      published <- rm_between(test[[i]][2], "Published: ", " - ", extract=TRUE)
      # characters <- rm_between(test[[i]][2], "Published: (.)+ -", " - ", extract=TRUE) ### not done

      if(isTRUE(str_count(updated, "/")==1)){
        updated <- paste0(updated,"/",as.character(year(Sys.Date())))
      } else {
        updated<-updated
      }
      
      if(isTRUE(str_count(published, "/")==1)){
        published <- paste0(published,"/", as.character(year(Sys.Date())))
      } else {
        published<-published
      }
      ##### throwing error when making the data frame
      full$name[i]<- name
      full$author[i]<- author
      full$description[i]<- description
      full$rating[i]<- rating
      full$language[i]<- language
      full$theme[i]<- theme
      full$chapters[i]<- chapters
      full$words[i]<- words
      full$reviews[i] <- reviews
      full$favs[i]<- favs
      full$follows[i]<- follows
      full$updated[i]<- updated
      full$published[i]<- published
      # full$characters[i]<- characters
      # full <- rbind(full, full_entry)
    }
    return(full)
  }
  
  if (typeof(entries) == "character") {
    full <- makeDF(entries)
  } else if (typeof(entries) == "list"){
    full <- lapply(entries, makeDF) %>% bind_rows()
  }

  
  return(full)
}

#--------------------------------------------------------------------------------------------
#--------------------------------------------------
# The actual function!!!!
#--------------------------------------------------
final <- function(story, type, max.entries=NA) {
  library(rvest)
  library(stringr)
  library(lubridate)
  library(dplyr)
  return(all_entries(getEntries(getPages(getUrl(story,type, max.entries)))))
}

### Test
ttt <- final("Zoolander", "movie")
#--------------------------------------------------------------------------------------------
